
@article{alom_history_2018,
	title = {The {History} {Began} from {AlexNet}: {A} {Comprehensive} {Survey} on {Deep} {Learning} {Approaches}},
	shorttitle = {The {History} {Began} from {AlexNet}},
	url = {http://arxiv.org/abs/1803.01164},
	abstract = {Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].},
	urldate = {2020-05-13},
	journal = {arXiv:1803.01164 [cs]},
	author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
	month = sep,
	year = {2018},
	note = {arXiv: 1803.01164},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 39 pages, 46 figures, 3 tables. arXiv admin note: text overlap with arXiv:1408.3264, arXiv:1411.4046},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\ZYZBEGQ5\\Alom et al. - 2018 - The History Began from AlexNet A Comprehensive Su.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\NHYSLL8Q\\1803.html:text/html}
}

@article{wason_deep_2018,
	title = {Deep learning: {Evolution} and expansion},
	volume = {52},
	issn = {13890417},
	shorttitle = {Deep learning},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389041717303546},
	doi = {10.1016/j.cogsys.2018.08.023},
	language = {en},
	urldate = {2020-05-13},
	journal = {Cognitive Systems Research},
	author = {Wason, Ritika},
	month = dec,
	year = {2018},
	pages = {701--708}
}

@article{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	language = {en},
	number = {3},
	urldate = {2020-05-13},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	pages = {211--252},
	file = {Texte int√©gral:C\:\\Users\\Guigui\\Zotero\\storage\\ABECK8LB\\Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf:application/pdf}
}

@article{shawahna_fpga-based_2019,
	title = {{FPGA}-{Based} {Accelerators} of {Deep} {Learning} {Networks} for {Learning} and {Classification}: {A} {Review}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {{FPGA}-{Based} {Accelerators} of {Deep} {Learning} {Networks} for {Learning} and {Classification}},
	doi = {10.1109/ACCESS.2018.2890150},
	abstract = {Due to recent advances in digital technologies, and availability of credible data, an area of artificial intelligence, deep learning, has emerged and has demonstrated its ability and effectiveness in solving complex learning problems not possible before. In particular, convolutional neural networks (CNNs) have demonstrated their effectiveness in the image detection and recognition applications. However, they require intensive CPU operations and memory bandwidth that make general CPUs fail to achieve the desired performance levels. Consequently, hardware accelerators that use application-specific integrated circuits, field-programmable gate arrays (FPGAs), and graphic processing units have been employed to improve the throughput of CNNs. More precisely, FPGAs have been recently adopted for accelerating the implementation of deep learning networks due to their ability to maximize parallelism and their energy efficiency. In this paper, we review the recent existing techniques for accelerating deep learning networks on FPGAs. We highlight the key features employed by the various techniques for improving the acceleration performance. In addition, we provide recommendations for enhancing the utilization of FPGAs for CNNs acceleration. The techniques investigated in this paper represent the recent trends in the FPGA-based accelerators of deep learning networks. Thus, this paper is expected to direct the future advances on efficient hardware accelerators and to be useful for deep learning researchers.},
	journal = {IEEE Access},
	author = {Shawahna, Ahmad and Sait, Sadiq M. and El-Maleh, Aiman},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Acceleration, Convolution, convolutional neural networks (CNNs), Field programmable gate arrays, Hardware, Adaptable architectures, deep learning, Deep learning, dynamic reconfiguration, energy-efficient architecture, field programmable gate arrays (FPGAs), hardware accelerator, machine learning, neural networks, Neural networks, optimization, parallel computer architecture, reconfigurable computing, Throughput},
	pages = {7823--7859},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Guigui\\Zotero\\storage\\IKNRASL5\\Shawahna et al. - 2019 - FPGA-Based Accelerators of Deep Learning Networks .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Guigui\\Zotero\\storage\\PFC87ULN\\8594633.html:text/html}
}

@article{liu_uniform_2019,
	title = {A {Uniform} {Architecture} {Design} for {Accelerating} {2D} and {3D} {CNNs} on {FPGAs}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2079-9292/8/1/65},
	doi = {10.3390/electronics8010065},
	abstract = {Three-dimensional convolutional neural networks (3D CNNs) have gained popularity in many complicated computer vision applications. Many customized accelerators based on FPGAs are proposed for 2D CNNs, while very few are for 3D CNNs. Three-D CNNs are far more computationally intensive and the design space for 3D CNN acceleration has been further expanded since one more dimension is introduced, making it a big challenge to accelerate 3D CNNs on FPGAs. Motivated by the finding that the computation patterns of 2D and 3D CNNs are very similar, we propose a uniform architecture design for accelerating both 2D and 3D CNNs in this paper. The uniform architecture is based on the idea of mapping convolutions to matrix multiplications. A customized mapping module is developed to generate the feature matrix tilings with no need to store the entire enlarged feature matrix on-chip or off-chip, a splitting strategy is adopted to reconstruct a convolutional layer to adapt to the on-chip memory capacity, and a 2D multiply-and-accumulate (MAC) array is adopted to compute matrix multiplications efficiently. For demonstration, we implement an accelerator prototype with a high-level synthesis (HLS) methodology on a Xilinx VC709 board and test the accelerator on three typical CNN models: AlexNet, VGG16, and C3D. Experimental results show that the accelerator achieves state-of-the-art throughput performance on both 2D and 3D CNNs, with much better energy efficiency than the CPU and GPU.},
	language = {en},
	number = {1},
	urldate = {2020-05-13},
	journal = {Electronics},
	author = {Liu, Zhiqiang and Chow, Paul and Xu, Jinwei and Jiang, Jingfei and Dou, Yong and Zhou, Jie},
	month = jan,
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {accelerator, FPGA, 2D CNN, 2D MAC array, 3D CNN, HLS, matrix multiplication, uniform architecture},
	pages = {65},
	file = {Full Text PDF:C\:\\Users\\Guigui\\Zotero\\storage\\2DEBA54J\\Liu et al. - 2019 - A Uniform Architecture Design for Accelerating 2D .pdf:application/pdf;Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\68SKUNIS\\htm.html:text/html}
}

@book{brain_perceptron_nodate,
	title = {The {Perceptron}: {A} {Probabilistic} {Model} for {Information} {Storage} and {Organization}},
	shorttitle = {The {Perceptron}},
	abstract = {If we are eventually to understand the capability of higher organisms for perceptual recognition, generalization, recall, and thinking, we must first have answers to three fundamental questions: 1. How is information about the physical world sensed, or detected, by the biological system? 2. In what form is information stored, or remembered? 3. How does information contained in storage, or in memory, influence recognition and behavior? The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus 1 The development of this theory has been carried out at the Cornell Aeronautical Laboratory, Inc., under the sponsorship of the Office of Naval Research, Contract Nonr-2381(00). This article is primarily'an adaptation of material reported in Ref. IS, which constitutes the first full report on the program.},
	author = {Brain, In The and Rosenblatt, F.},
	file = {Citeseer - Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\4SLW8XXQ\\summary.html:text/html;Citeseer - Full Text PDF:C\:\\Users\\Guigui\\Zotero\\storage\\WXDBN2BV\\Brain et Rosenblatt - The Perceptron A Probabilistic Model for Informat.pdf:application/pdf}
}

@article{khan_survey_2020,
	title = {A {Survey} of the {Recent} {Architectures} of {Deep} {Convolutional} {Neural} {Networks}},
	issn = {0269-2821, 1573-7462},
	url = {http://arxiv.org/abs/1901.06032},
	doi = {10.1007/s10462-020-09825-6},
	abstract = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
	language = {en},
	urldate = {2020-06-06},
	journal = {Artificial Intelligence Review},
	author = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
	month = apr,
	year = {2020},
	note = {arXiv: 1901.06032},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Number of Pages: 70, Number of Figures: 11, Number of Tables: 11. Artif Intell Rev (2020)},
	file = {1901.06032.pdf:C\:\\Users\\Guigui\\Zotero\\storage\\YNJTSKEN\\1901.06032.pdf:application/pdf}
}

@book{mitchell_machine_1997,
	address = {New York},
	series = {{McGraw}-{Hill} series in computer science},
	title = {Machine {Learning}},
	isbn = {978-0-07-042807-2},
	language = {en},
	publisher = {McGraw-Hill},
	author = {Mitchell, Tom M.},
	year = {1997},
	keywords = {Computer algorithms, Machine learning},
	file = {Mitchell - 1997 - Machine Learning.pdf:C\:\\Users\\Guigui\\Zotero\\storage\\QN6IL4V7\\Mitchell - 1997 - Machine Learning.pdf:application/pdf}
}

@book{russell_artificial_2009,
	edition = {3},
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}},
	shorttitle = {Artificial {Intelligence}},
	abstract = {This is the eBook of the printed book and may not include anymedia, website access codes, or print supplements that may comepackaged with the bound book.Artificial Intelligence: A ModernApproach, 3e offers the most comprehensive, up-to-dateintroduction to the theory and practice of artificial intelligence.Number one in its field, this textbook is ideal for one ortwo-semester, undergraduate or graduate-level courses in ArtificialIntelligence.Dr. Peter Norvig, contributing ArtificialIntelligence author and ProfessorSebastian Thrun, a Pearson author are offering a free online course atStanford University on artificial intelligence.According to an article in The New York Times, the course on artificial intelligenceis ‚Äúone of three being offered experimentally by the Stanfordcomputer science department to extend technology knowledge andskills beyond this elite campus to the entire world.‚Äù One ofthe other two courses, an introduction to database software, is being taughtby Pearson author Dr. Jennifer Widom.Artificial Intelligence: A Modern Approach, 3e is availableto purchase as an eText for your Kindle‚Ñ¢, NOOK‚Ñ¢, andthe iPhone¬Æ/iPad¬Æ.To learn more about the course on artificial intelligence, visithttp://www.ai-class.com. To read thefull New York Times article, click here.},
	language = {English},
	publisher = {Prentice Hall},
	author = {Russell, Peter Norvig Stuart},
	month = dec,
	year = {2009}
}

@article{arnold_introduction_2011,
	title = {An {Introduction} to {Deep} {Learning}},
	abstract = {The deep learning paradigm tackles problems on which shallow architectures (e.g. SVM) are aÔ¨Äected by the curse of dimensionality. As part of a two-stage learning scheme involving multiple layers of nonlinear processing a set of statistically robust features is automatically extracted from the data. The present tutorial introducing the ESANN deep learning special session details the state-of-the-art models and summarizes the current understanding of this learning approach which is a reference for many diÔ¨Écult classiÔ¨Åcation tasks.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Arnold, Ludovic and Rebecchi, S√©bastien and Chevallier, Sylvain and Paugam-Moisy, H√©l√®ne},
	year = {2011},
	pages = {12},
	file = {Arnold et al. - 2011 - An Introduction to Deep Learning.pdf:C\:\\Users\\Guigui\\Zotero\\storage\\VM42ZWFS\\Arnold et al. - 2011 - An Introduction to Deep Learning.pdf:application/pdf}
}

@article{abdelouahab_accelerating_2018,
	title = {Accelerating {CNN} inference on {FPGAs}: {A} {Survey}},
	shorttitle = {Accelerating {CNN} inference on {FPGAs}},
	url = {http://arxiv.org/abs/1806.01683},
	abstract = {Convolutional Neural Networks (CNNs) are currently adopted to solve an ever greater number of problems, ranging from speech recognition to image classification and segmentation. The large amount of processing required by CNNs calls for dedicated and tailored hardware support methods. Moreover, CNN workloads have a streaming nature, well suited to reconfigurable hardware architectures such as FPGAs. The amount and diversity of research on the subject of CNN FPGA acceleration within the last 3 years demonstrates the tremendous industrial and academic interest. This paper presents a state-of-the-art of CNN inference accelerators over FPGAs. The computational workloads, their parallelism and the involved memory accesses are analyzed. At the level of neurons, optimizations of the convolutional and fully connected layers are explained and the performances of the different methods compared. At the network level, approximate computing and datapath optimization methods are covered and state-of-the-art approaches compared. The methods and tools investigated in this survey represent the recent trends in FPGA CNN inference accelerators and will fuel the future advances on efficient hardware deep learning.},
	urldate = {2020-06-12},
	journal = {arXiv:1806.01683 [cs]},
	author = {Abdelouahab, Kamel and Pelcat, Maxime and Serot, Jocelyn and Berry, Fran√ßois},
	month = may,
	year = {2018},
	note = {arXiv: 1806.01683},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Hardware Architecture, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: Cloning our HAL submission in ArXiv, Technical Report - Universite Clermont Auvergne, January 2018},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\876PLGFW\\Abdelouahab et al. - 2018 - Accelerating CNN inference on FPGAs A Survey.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\PTFWQVUY\\1806.html:text/html}
}

@article{zhu_efficient_2020,
	title = {An {Efficient} {Hardware} {Accelerator} for {Structured} {Sparse} {Convolutional} {Neural} {Networks} on {FPGAs}},
	url = {http://arxiv.org/abs/2001.01955},
	abstract = {Deep Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in a wide range of applications. However, deeper CNN models, which are usually computation consuming, are widely required for complex Artificial Intelligence (AI) tasks. Though recent research progress on network compression such as pruning has emerged as a promising direction to mitigate computational burden, existing accelerators are still prevented from completely utilizing the benefits of leveraging sparsity owing to the irregularity caused by pruning. On the other hand, Field-Programmable Gate Arrays (FPGAs) have been regarded as a promising hardware platform for CNN inference acceleration. However, most existing FPGA accelerators focus on dense CNN and cannot address the irregularity problem. In this paper, we propose a sparse wise dataflow to skip the cycles of processing Multiply-and-Accumulates (MACs) with zero weights and exploit data statistics to minimize energy through zeros gating to avoid unnecessary computations. The proposed sparse wise dataflow leads to a low bandwidth requirement and a high data sharing. Then we design an FPGA accelerator containing a Vector Generator Module (VGM) which can match the index between sparse weights and input activations according to the proposed dataflow. Experimental results demonstrate that our implementation can achieve 987 imag/s and 48 imag/s performance for AlexNet and VGG-16 on Xilinx ZCU102, respectively, which provides 1.5x to 6.7x speedup and 2.0x to 6.2x energy-efficiency over previous CNN FPGA accelerators.},
	urldate = {2020-06-14},
	journal = {arXiv:2001.01955 [cs, eess]},
	author = {Zhu, Chaoyang and Huang, Kejie and Yang, Shuyuan and Zhu, Ziqi and Zhang, Hejia and Shen, Haibin},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.01955},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Systems and Control},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\UAE35WRB\\Zhu et al. - 2020 - An Efficient Hardware Accelerator for Structured S.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\9V9S7RGI\\2001.html:text/html}
}

@article{sze_efficient_2017,
	title = {Efficient {Processing} of {Deep} {Neural} {Networks}: {A} {Tutorial} and {Survey}},
	volume = {105},
	issn = {1558-2256},
	shorttitle = {Efficient {Processing} of {Deep} {Neural} {Networks}},
	doi = {10.1109/JPROC.2017.2761740},
	abstract = {Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.},
	number = {12},
	journal = {Proceedings of the IEEE},
	author = {Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S.},
	month = dec,
	year = {2017},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Computer architecture, neural nets, deep learning, machine learning, Neural networks, Machine learning, artificial intelligence, Artificial intelligence, ASIC, Benchmark testing, Biological neural networks, computation cost reduction, computational complexity, computer architecture, convolutional neural networks, Convolutional neural networks, dataflow processing, deep neural networks, DNN hardware designs, DNN hardware implementations, energy efficiency, energy-efficient accelerators, hardware architecture, hardware cost, hardware design changes, hardware platforms, low power, Neurons, spatial architectures, Tutorials, VLSI},
	pages = {2295--2329},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Guigui\\Zotero\\storage\\KH2XTFH7\\8114708.html:text/html;Version soumise:C\:\\Users\\Guigui\\Zotero\\storage\\U9QZ6DCD\\Sze et al. - 2017 - Efficient Processing of Deep Neural Networks A Tu.pdf:application/pdf}
}

@book{winograd_arithmetic_1980,
	series = {{CBMS}-{NSF} {Regional} {Conference} {Series} in {Applied} {Mathematics}},
	title = {Arithmetic {Complexity} of {Computations}},
	isbn = {978-0-89871-163-9},
	url = {https://books.google.be/books?id=eWb9EF7BmCYC},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Winograd, S.},
	year = {1980},
	lccn = {lc79093154}
}

@article{lavin_fast_2015,
	title = {Fast {Algorithms} for {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1509.09308},
	abstract = {Deep convolutional neural networks take GPU days of compute time to train on large data sets. Pedestrian detection for self driving cars requires very low latency. Image recognition for mobile phones is constrained by limited processing resources. The success of convolutional neural networks in these situations is limited by how fast we can compute them. Conventional FFT based convolution is fast for large filters, but state of the art convolutional neural networks use small, 3x3 filters. We introduce a new class of fast algorithms for convolutional neural networks using Winograd's minimal filtering algorithms. The algorithms compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes. We benchmark a GPU implementation of our algorithm with the VGG network and show state of the art throughput at batch sizes from 1 to 64.},
	urldate = {2020-06-14},
	journal = {arXiv:1509.09308 [cs]},
	author = {Lavin, Andrew and Gray, Scott},
	month = nov,
	year = {2015},
	note = {arXiv: 1509.09308},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning, F.2.1, I.2.6},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\2EHFQVVI\\Lavin et Gray - 2015 - Fast Algorithms for Convolutional Neural Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\CBH9KBUK\\1509.html:text/html}
}

@article{sandler_mobilenetv2_2019,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	shorttitle = {{MobileNetV2}},
	url = {http://arxiv.org/abs/1801.04381},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. The MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters},
	urldate = {2020-06-14},
	journal = {arXiv:1801.04381 [cs]},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	month = mar,
	year = {2019},
	note = {arXiv: 1801.04381},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\LNCAJF9C\\Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\QMYJJDFJ\\1801.html:text/html}
}

@inproceedings{jong_hwan_ko_design_2017,
	title = {Design of an energy-efficient accelerator for training of convolutional neural networks using frequency-domain computation},
	doi = {10.1145/3061639.3062228},
	abstract = {Convolutional neural networks (CNNs) require high computation and memory demand for training. This paper presents the design of a frequency-domain accelerator for energy-efficient CNN training. With Fourier representations of parameters, we replace convolutions with simpler pointwise multiplications. To eliminate the Fourier transforms at every layer, we train the network entirely in the frequency domain using approximate frequency-domain nonlinear operations. We further reduce computation and memory requirements using sinc interpolation and Hermitian symmetry. The accelerator is designed and synthesized in 28nm CMOS, as well as prototyped in an FPGA. The simulation results show that the proposed accelerator significantly reduces training time and energy for a target recognition accuracy.},
	booktitle = {2017 54th {ACM}/{EDAC}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	author = {Jong Hwan Ko and Mudassar, Burhan and Na, Taesik and Mukhopadhyay, Saibal},
	month = jun,
	year = {2017},
	keywords = {convolutional neural network (CNN), FPGA, convolutional neural networks, approximate frequency-domain nonlinear operations, CMOS, energy-efficient accelerator, energy-efficient CNN training, Fourier representations, Fourier transforms, frequency domain, frequency-domain accelerator, frequency-domain analysis, frequency-domain computation, Hermitian symmetry, interpolation, memory demand, memory requirements, neural chips, pointwise multiplications, sinc interpolation, size 28.0 nm, training},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Guigui\\Zotero\\storage\\H6WAI994\\8060431.html:text/html}
}

@book{w_smith_scientist_1997,
	edition = {1},
	title = {The {Scientist} and {Engineer}'s {Guide} to {Digital} {Signal} {Processing}'s {Table} of {Content}},
	isbn = {0-9660176-3-3},
	url = {https://www.dspguide.com/pdfbook.htm},
	urldate = {2020-06-14},
	publisher = {California Technical Pub},
	author = {W. Smith, Steven},
	year = {1997},
	file = {The Scientist and Engineer's Guide to Digital Signal Processing's Table of Content:C\:\\Users\\Guigui\\Zotero\\storage\\H7S4Y995\\pdfbook.html:text/html}
}

@inproceedings{gokhale_240_2014,
	title = {A 240 {G}-ops/s {Mobile} {Coprocessor} for {Deep} {Neural} {Networks}},
	doi = {10.1109/CVPRW.2014.106},
	abstract = {Deep networks are state-of-the-art models used for understanding the content of images, videos, audio and raw input data. Current computing systems are not able to run deep network models in real-time with low power consumption. In this paper we present nn-X: a scalable, low-power coprocessor for enabling real-time execution of deep neural networks. nn-X is implemented on programmable logic devices and comprises an array of configurable processing elements called collections. These collections perform the most common operations in deep networks: convolution, subsampling and non-linear functions. The nn-X system includes 4 high-speed direct memory access interfaces to DDR3 memory and two ARM Cortex-A9 processors. Each port is capable of a sustained throughput of 950 MB/s in full duplex. nn-X is able to achieve a peak performance of 227 G-ops/s, a measured performance in deep learning applications of up to 200 G-ops/s while consuming less than 4 watts of power. This translates to a performance per power improvement of 10 to 100 times that of conventional mobile and desktop processors.},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Gokhale, Vinayak and Jin, Jonghoon and Dundar, Aysegul and Martini, Berin and Culurciello, Eugenio},
	month = jun,
	year = {2014},
	note = {ISSN: 2160-7516},
	keywords = {Convolution, convolution operation, neural nets, machine learning, convolutional neural networks, deep neural networks, ARM Cortex-A9 processors, Artificial neural networks, Computer vision, configurable processing elements, coprocessors, Coprocessors, DDR3 memory, desktop processors, embedded vision system, hardware acceleration, memory access interface, Memory management, mobile coprocessor, mobile processors, nn-X coprocessor, nonlinear function operation, Performance evaluation, power consumption, Program processors, programmable logic devices, subsampling operation},
	pages = {696--701},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Guigui\\Zotero\\storage\\YFXF2RWP\\6910056.html:text/html}
}

@article{abdelouahab_tactics_2017,
	title = {Tactics to {Directly} {Map} {CNN} graphs on {Embedded} {FPGAs}},
	volume = {9},
	url = {https://hal.archives-ouvertes.fr/hal-01626462},
	doi = {10.1109/LES.2017.2743247},
	abstract = {Deep Convolutional Neural Networks (CNNs) are the state-of-the-art in image classification. Since CNN feed forward propagation involves highly regular parallel computation, it benefits from a significant speed-up when running on fine grain parallel programmable logic devices. As a consequence, several studies have proposed FPGA-based accelerators for CNNs. However, because of the large computationalpower required by CNNs, none of the previous studies has proposed a direct mapping of the CNN onto the physical resources of an FPGA, allocating each processing actor to its own hardware instance.In this paper, we demonstrate the feasibility of the so called direct hardware mapping (DHM) and discuss several tactics we explore to make DHM usable in practice. As a proof of concept, we introduce the HADDOC2 open source tool, that automatically transforms a CNN description into a synthesizable hardware description with platform-independent direct hardware mapping.},
	number = {4},
	urldate = {2020-06-15},
	journal = {IEEE Embedded Systems Letters},
	author = {ABDELOUAHAB, Kamel and Pelcat, Maxime and S√©rot, Jocelyn and Bourrasset, C√©dric and Berry, Fran√ßois},
	year = {2017},
	note = {Publisher: Institute of Electrical and Electronics Engineers},
	keywords = {FPGA, CNN, Deep Learning, VHDL generator},
	pages = {113 -- 116},
	file = {HAL PDF Full Text:C\:\\Users\\Guigui\\Zotero\\storage\\PG63QE8E\\ABDELOUAHAB et al. - 2017 - Tactics to Directly Map CNN graphs on Embedded FPG.pdf:application/pdf}
}

@inproceedings{lin_li_low_2016,
	title = {Low power design methodology for signal processing systems using lightweight dataflow techniques},
	doi = {10.1109/DASIP.2016.7853801},
	abstract = {Dataflow modeling techniques facilitate many aspects of design exploration and optimization for signal processing systems, such as efficient scheduling, memory management, and task synchronization. The lightweight dataflow (LWDF) programming methodology provides an abstract programming model that supports dataflow-based design and implementation of signal processing hardware and software components and systems. Previous work on LWDF techniques has emphasized their application to DSP software implementation. In this paper, we present new extensions of the LWDF methodology for effective integration with hardware description languages (HDLs), and we apply these extensions to develop efficient methods for low power DSP hardware implementation. Through a case study of a deep neural network application for vehicle classification, we demonstrate our proposed LWDF-based hardware design methodology, and its effectiveness in low power implementation of complex signal processing systems.},
	booktitle = {2016 {Conference} on {Design} and {Architectures} for {Signal} and {Image} {Processing} ({DASIP})},
	author = {Lin Li and Fanni, Tiziana and Viitanen, Timo and Renjie Xie and Palumbo, Francesca and Raffo, Luigi and Huttunen, Heikki and Takala, Jarmo and Bhattacharyya, Shuvra S.},
	month = oct,
	year = {2016},
	keywords = {Hardware, neural nets, complex signal processing systems, data flow analysis, dataflow modeling techniques, dataflow-based design, deep neural network application, Design methodology, Digital signal processing, digital signal processing chips, DSP software implementation, hardware description languages, Hardware design languages, HDLs, lightweight dataflow programming methodology, LWDF programming methodology, Ports (Computers), power DSP hardware implementation, Programming, signal processing, Standards, vehicle classification},
	pages = {82--89},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Guigui\\Zotero\\storage\\KDVMBU3D\\7853801.html:text/html}
}

@article{iandola_squeezenet_2016,
	title = {{SqueezeNet}: {AlexNet}-level accuracy with 50x fewer parameters and {\textless}0.{5MB} model size},
	shorttitle = {{SqueezeNet}},
	url = {http://arxiv.org/abs/1602.07360},
	abstract = {Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet},
	urldate = {2020-06-17},
	journal = {arXiv:1602.07360 [cs]},
	author = {Iandola, Forrest N. and Han, Song and Moskewicz, Matthew W. and Ashraf, Khalid and Dally, William J. and Keutzer, Kurt},
	month = nov,
	year = {2016},
	note = {arXiv: 1602.07360},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: In ICLR Format},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\R7FTFBXE\\Iandola et al. - 2016 - SqueezeNet AlexNet-level accuracy with 50x fewer .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\QZTUFVJH\\1602.html:text/html}
}

@article{han_deep_2016,
	title = {Deep {Compression}: {Compressing} {Deep} {Neural} {Networks} with {Pruning}, {Trained} {Quantization} and {Huffman} {Coding}},
	shorttitle = {Deep {Compression}},
	url = {http://arxiv.org/abs/1510.00149},
	abstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce "deep compression", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.},
	urldate = {2020-06-17},
	journal = {arXiv:1510.00149 [cs]},
	author = {Han, Song and Mao, Huizi and Dally, William J.},
	month = feb,
	year = {2016},
	note = {arXiv: 1510.00149},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Published as a conference paper at ICLR 2016 (oral)},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\JJ9WLATZ\\Han et al. - 2016 - Deep Compression Compressing Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\D84DRTH5\\1510.html:text/html}
}

@article{zoph_learning_2018,
	title = {Learning {Transferable} {Architectures} for {Scalable} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1707.07012},
	abstract = {Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (the "NASNet search space") which enables transferability. In our experiments, we search for the best convolutional layer (or "cell") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, named "NASNet architecture". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, NASNet achieves 2.4\% error rate, which is state-of-the-art. On ImageNet, NASNet achieves, among the published works, state-of-the-art accuracy of 82.7\% top-1 and 96.2\% top-5 on ImageNet. Our model is 1.2\% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28\% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74\% top-1 accuracy, which is 3.1\% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0\% achieving 43.1\% mAP on the COCO dataset.},
	urldate = {2020-06-17},
	journal = {arXiv:1707.07012 [cs, stat]},
	author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
	month = apr,
	year = {2018},
	note = {arXiv: 1707.07012},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\FUWH4Q73\\Zoph et al. - 2018 - Learning Transferable Architectures for Scalable I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\VSNL9FGA\\1707.html:text/html}
}

@inproceedings{zhang_shufflenet_2018,
	address = {Salt Lake City, UT},
	title = {{ShuffleNet}: {An} {Extremely} {Efficient} {Convolutional} {Neural} {Network} for {Mobile} {Devices}},
	isbn = {978-1-5386-6420-9},
	shorttitle = {{ShuffleNet}},
	url = {https://ieeexplore.ieee.org/document/8578814/},
	doi = {10.1109/CVPR.2018.00716},
	abstract = {We introduce an extremely computation-efÔ¨Åcient CNN architecture named ShufÔ¨ÇeNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shufÔ¨Çe, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classiÔ¨Åcation and MS COCO object detection demonstrate the superior performance of ShufÔ¨ÇeNet over other structures, e.g. lower top-1 error (absolute 7.8\%) than recent MobileNet [12] on ImageNet classiÔ¨Åcation task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShufÔ¨ÇeNet achieves ‚àº13√ó actual speedup over AlexNet while maintaining comparable accuracy.},
	language = {en},
	urldate = {2020-06-17},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
	month = jun,
	year = {2018},
	pages = {6848--6856},
	file = {Zhang et al. - 2018 - ShuffleNet An Extremely Efficient Convolutional N.pdf:C\:\\Users\\Guigui\\Zotero\\storage\\55EQ86WN\\Zhang et al. - 2018 - ShuffleNet An Extremely Efficient Convolutional N.pdf:application/pdf}
}

@article{qasaimeh_comparing_2019,
	title = {Comparing {Energy} {Efficiency} of {CPU}, {GPU} and {FPGA} {Implementations} for {Vision} {Kernels}},
	url = {http://arxiv.org/abs/1906.11879},
	abstract = {Developing high performance embedded vision applications requires balancing run-time performance with energy constraints. Given the mix of hardware accelerators that exist for embedded computer vision (e.g. multi-core CPUs, GPUs, and FPGAs), and their associated vendor optimized vision libraries, it becomes a challenge for developers to navigate this fragmented solution space. To aid with determining which embedded platform is most suitable for their application, we conduct a comprehensive benchmark of the run-time performance and energy efficiency of a wide range of vision kernels. We discuss rationales for why a given underlying hardware architecture innately performs well or poorly based on the characteristics of a range of vision kernel categories. Specifically, our study is performed for three commonly used HW accelerators for embedded vision applications: ARM57 CPU, Jetson TX2 GPU and ZCU102 FPGA, using their vendor optimized vision libraries: OpenCV, VisionWorks and xfOpenCV. Our results show that the GPU achieves an energy/frame reduction ratio of 1.1-3.2x compared to the others for simple kernels. While for more complicated kernels and complete vision pipelines, the FPGA outperforms the others with energy/frame reduction ratios of 1.2-22.3x. It is also observed that the FPGA performs increasingly better as a vision application's pipeline complexity grows.},
	urldate = {2020-06-17},
	journal = {arXiv:1906.11879 [cs, eess]},
	author = {Qasaimeh, Murad and Denolf, Kristof and Lo, Jack and Vissers, Kees and Zambreno, Joseph and Jones, Phillip H.},
	month = may,
	year = {2019},
	note = {arXiv: 1906.11879},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: 8 pages, Design Automation Conference (DAC), The 15th IEEE International Conference on Embedded Software and Systems, 2019},
	file = {arXiv Fulltext PDF:C\:\\Users\\Guigui\\Zotero\\storage\\CUYP8DAD\\Qasaimeh et al. - 2019 - Comparing Energy Efficiency of CPU, GPU and FPGA I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Guigui\\Zotero\\storage\\WGFMBFSP\\1906.html:text/html}
}
