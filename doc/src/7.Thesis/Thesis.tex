\chapter{Accelerating Convolutional Neural Networks for FPGA using Depthwise Separable Convolution and Pruning} \label{chap:pratique}
%
%
In the previous chapter, we introduced pruning, which reduces both size and computational complexity of \acrshort{cnn}s. We also showed that there exist various pruning schemes. Each of them can be categorized from coarse-grained to fine-grained. Coarse-grained pruning schemes have the advantage that they can be easily implemented on \acrshort{gpu} and \acrshort{cpu} in exchange for a drop of accuracy. On the other hand, fine-grained pruning schemes can limit this reduction of accuracy but can create irregular access pattern that makes them difficult to implement on such platforms. 

To have an efficient \acrshort{fpga}-based accelerator, we should focus on implementing the most fine-grained pruning scheme possible to apply a high sparsity while limiting the loss of accuracy. This shows the advantage of using \acrshort{fpga} accelerator because, as said previously, this type of pruning scheme is not easily implementable on \acrshort{cpu} and \acrshort{gpu}

In this chapter, we define an \acrshort{fpga}-based accelerator architecture that integrates both pruning and \acrshort{dsc} (see Section \ref{subs:dsc}) to reduce the number of weights and operations. To show its applicability, this architecture implements a state-of-the-art network that includes \acrshort{dsc} and targets an embedded platform: MobileNetV2 (Sections \ref{subs:mbv2} and \ref{subsec:mdopti}). Since the pruning can cause degradation of the performance, we have to determine the design objectives of the architecture and its associated pruning scheme, which are the following:
%
\begin{enumerate}
    \item The pruning scheme is as fine-grained as possible.
    \item The pruning scheme reduces the computational complexity.
    \item The pruning scheme allows for a reduction of the memory required to store the weights.
    \item The proposed architecture provides a logically correct output.
    \item An increase in the sparsity improves the performance of the architecture.
\end{enumerate}

Moreover, the \acrshort{fpga}-based accelerator architecture is implemented on a Cyclone V \acrshort{fpga}.

Section \ref{sec:design} aims at developing the pruning scheme and the algorithm to handle it. We also define in this section the weight and operation reduction factors obtained when applying the proposed pruning scheme. We also define a weight compressed format to reduce weight memory use. We then perform a loop analysis on the proposed algorithm to determine the optimal hardware design variables and the structure of the architecture.

Section \ref{sec:implementation} describes the implementation of the \acrshort{fpga}-based accelerator architecture and details its dataflow. We start by explaining the overall architecture and then we go in more details into each of its components.

Section \ref{sec:measure} shows the results obtained and discusses if the proposed design objectives are met.
%
\input{src/7.Thesis/Architecture}
%
%
\input{src/7.Thesis/Implementation}
%
%
\input{src/7.Thesis/Measure}
%
%
\newpage
